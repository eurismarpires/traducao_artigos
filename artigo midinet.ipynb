{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstract\n",
    "\n",
    "Neste artigo, apresentamos MidiNet, uma rede neural convoluta profunda (CNN)\n",
    "Baseada na rede adversária generativa (GAN) que se destina a fornecer uma visão geral,\n",
    "Estrutura de rede altamente adaptável para geração de música de domínio simbólico. o\n",
    "A rede leva o ruído aleatório como entrada e gera uma seqüência de melodia uma medida\n",
    "(Bar) após o outro. Além disso, tem um novo sub-modelo CNN reflexivo que\n",
    "Nos permite orientar o processo de geração fornecendo não só 1D, mas também 2D\n",
    "Condições. Em nossa implementação, usamos o acorde pretendido da barra atual\n",
    "Como uma condição 1D para fornecer um contexto harmônico, e a melodia gerada para o\n",
    "Antes da barra anteriormente como uma condição 2D para fornecer informações seqüenciais. o\n",
    "A saída da rede é uma matriz de 16 por 128 cada vez, representando a presença de\n",
    "Cada uma das 128 notas MIDI na sequência de melodia gerada dessa barra, com a\n",
    "A menor unidade temporal é a décima sexta nota. MidiNet pode gerar música de\n",
    "Número arbitrário de barras, concatenando estas 16 por 128 matrizes. A melodia\n",
    "A sequência pode então ser reproduzida com um sintetizador. Nós fornecemos exemplos de clipes\n",
    "Mostrando a eficácia da MidiNet na geração de música harmônica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "As redes adversárias generativas (GANs) [1, 2] ganharam uma tremenda atenção nos últimos anos.\n",
    "Em um GAN, um modelo de gerador e um modelo discriminador são treinados simultaneamente sob o\n",
    "Conceito de minimax de dois jogadores de teoria dos jogos. O modelo do gerador visa produzir dados artificiais\n",
    "Isso poderia enganar o modelo discriminador, enquanto a tarefa do modelo discriminador é distinguir\n",
    "Entre dados autênticos e artificiais. Para a diversidade do resultado da geração, a entrada para o\n",
    "O modelo do gerador geralmente é um ruído aleatório. O modelo do gerador em um GAN bem-sucedido pode converter\n",
    "Um ruído aleatório dado em algo que parece ser realista para o ser humano. Pode ser uma imagem, texto\n",
    "Passagem ou clipe de som, dependendo dos dados de treinamento. Até à data, a maioria dos trabalhos existentes tem\n",
    "Focado na geração de imagens usando GANs [3-5].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para modelar a natureza temporal da música, uma série de trabalhos anteriores sobre geração de música são baseados em\n",
    "Redes neurais recorrentes (RNNs) [6-10]. Embora essas RNNs às vezes possam produzir\n",
    "Música, o treinamento de uma RNN geralmente é mais lento, em comparação com o de um neural convolucional\n",
    "Rede (CNN) [11]. Também é menos direto adicionar restrições ou reguladores a uma RNN para informar o processo de geração com conhecimento musical a priori, que pode ser essencial para a qualidade estética do resultado da geração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste artigo é propor um modelo GAN novo para geração de música de domínio simbólico que\n",
    "É baseado na CNN, com foco na geração da sequência de melodia principal.2\n",
    "Em vez de gerar um\n",
    "Sequência de melodia continuamente, propomos gerar uma melodia uma medida (barra) após a outra,\n",
    "De forma sucessiva. Isso nos permite usar uma matriz 2D que represente a ocorrência de diferentes\n",
    "Notas ao longo do tempo como entrada para uma CNN. Além disso, aproveitando a idéia de contraditório condicional\n",
    "Treinamento [5, 11, 12], propomos um novo sub-modelo CNN reflexivo que usa a sequência de melodia\n",
    "Gerado anteriormente para a barra anterior (que é novamente representada como uma matriz 2D) para condicionar\n",
    "A geração para a barra atual. Desta forma, a dependência temporal entre as melodias de\n",
    "As barras sucessivas podem ser modeladas sem uma unidade recorrente, como é usado nas RNNs. A CNN reflexiva\n",
    "Realmente nos permite usar as seqüências de melodia de várias barras anteriores para condicionar o GAN, para\n",
    "Modelo de dependências temporais de longo prazo na música. Além de tais condições 2D, certamente podemos\n",
    "Use as condições 1D mais simples (por exemplo, rótulos de classe), bem como para condicionar o GAN. Em outras palavras,\n",
    "Dependendo da informação a priori que possamos, podemos adicionar diferentes componentes ao nosso GAN. este\n",
    "Estrutura altamente adaptativa pode ser útil em vista dos padrões temporais complexos e hierárquicos (em\n",
    "Tempo) e relações harmônicas (entre a melodia principal e os sons simultâneos e acompanhantes)\n",
    "Encontrado na música. Nos referimos a este novo modelo CNN-GAN como MidiNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que, enquanto as condições de 1D foram amplamente utilizadas no trabalho anterior no GAN [5, 11, 12], a\n",
    "O uso de uma condição 2D não foi tentado antes, conforme nosso conhecimento. O proposto\n",
    "CNN reflexiva é necessária para adicionar essa condição 2D às camadas intermediárias de uma CNN, cada uma das\n",
    "Que tem tamanhos diferentes. Embora usemos tais condições 2D para a aplicação específica de símbolos simbólicos\n",
    "Geração de música de domínio, a idéia é realmente genérica e é aplicável a outros problemas\n",
    "também. Ele abre nova porta para incluir informações laterais aos GANs. Mais detalhes do método são\n",
    "Descrito na Seção 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nossa implementação (consulte a Seção 3), reunimos 1.022 guias MIDI para treinar a MidiNet. Nós costumavamos\n",
    "A informação da corda como a condição 1D, assumindo que a seqüência de corda desejada é dada e\n",
    "Que há apenas um acorde por barra. Além disso, a partir da segunda barra, usamos a melodia\n",
    "Sequência gerada para a barra anterior como condição 2D. Em outras palavras, condicionamos a\n",
    "Geração da melodia para cada barra por um rótulo de corda e a melodia da barra anterior. Para\n",
    "Estabilizar as atualizações de treinamento do GAN, usamos técnicas como a correspondência de recursos\n",
    "E alinhamento de etiquetas unilateral [5]. MidiNet pode gerar música de número arbitrário de barras, por\n",
    "Concatenando a sequência de melodia gerada para cada barra. Definimos o número alvo de barras para 8\n",
    "E forneça exemplos do resultado da geração na Seção 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Generator model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao projetar CNNs para tarefas relacionadas à imagem, o uso de filtros convolucionais 2D para o aprendizado de recursos é comum [3,13]. Em contraste, para tarefas relacionadas ao áudio, às vezes é bom o suficiente para usar filtros convolucionais 1D, uma vez que os dados de áudio são seqüenciais [14, 15]. Portanto, usamos filtros da forma h-by-1 na última camada convolucional transposta, onde h indica o número de notas MIDI consideradas pela rede. Da mesma forma, a série de camadas convolucionais transpostas converte um vetor de valores aleatórios em uma matriz 2D da forma desejada h-by-w como a saída, o que corresponde à ocorrência de diferentes notas nas unidades temporais $w$. O tamanho dos filtros na primeira camada convolucional transposta é definido como 1-por-w. O modelo do gerador está ilustrado na Figura 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"midinet.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
